{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5801297-7051-4f95-8997-5ae94aa9e26d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hellollll Wordddddddddddld\n"
     ]
    }
   ],
   "source": [
    "print(\"Hellollll Wordddddddddddld\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc49233",
   "metadata": {},
   "source": [
    "This project attempts to make a memory agent, where the user can specify their context, and the agent can query it and load relevant sections. \n",
    "\n",
    "The format of the memory file is left to the agent to determine but we will encourage it to make lots of summaries and notes that will help it reconstruct \n",
    "previous events. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a630a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Hello, world!\"}]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
