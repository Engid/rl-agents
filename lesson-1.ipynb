{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61147451",
   "metadata": {},
   "source": [
    "uv init [project]\n",
    "uv add openai "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75003a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import instructor # formats in pydantic way for more providers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a88229f3",
   "metadata": {},
   "source": [
    "can models do well with psuedocode grammars? will had <[text | action]> in his xlm formatting \n",
    "\n",
    "- read the model cards for how models do with structured formatting\n",
    "\n",
    "evals generation:\n",
    "have an llm go through documents and write trivia questions/answers to simulate people asking questions and having an agent look up an answer \n",
    "\n",
    "have LLMS in lots of places of the pipeline avoids a lot of manual work\n",
    "\n",
    "DeepEval "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90cff34",
   "metadata": {},
   "source": [
    "project ideas:\n",
    "\n",
    "tool calls with Results, Noam interview said giving tools that let the model check for legal moves is good, but having actions that fail might be bad? so experiment with `CheckForLegalMoves` or `GetFiles` that only returns which files the model has access too..\n",
    "\n",
    "play with security ideas.. \n",
    "\n",
    "play with tool descriptions that have pre/post condition descritions\n",
    "\n",
    "play with psudo code to real code generation \n",
    "\n",
    "play with \"special file\" formats that break out a Prompt section and a Code section, where the LLM fills in the code (godbolt but for LLMs)\n",
    "\n",
    "\n",
    "\n",
    "--> \n",
    "\n",
    "document search: \n",
    "load a butload of fantasy lore into a vector db, and ask the ai to load the right context per the theme of the conversation \n",
    "\n",
    "- have an llm generate \"answers\" for evals, with the context-section\n",
    "\n",
    "-will: agentic search may work better if the tools allow fine-grained search in combination, \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e3c286",
   "metadata": {},
   "source": [
    "Assignmen idea 1:\n",
    "\n",
    "- Implement agentic search over a corpus \n",
    "- Set up Evals for how well the agent can pull in context based on the prompt\n",
    "\n",
    "## Example\n",
    "\n",
    "prompt: \"i have another idea for the project\"\n",
    "\n",
    "expected tool call: \n",
    "```JSON\n",
    "[\n",
    "    {\"tool\": \"get_history\", \"args\": [\"<span of last week>\"]}, \n",
    "    {\"tool\": \"search_keyword\", \"args\": [\"project\"]} \n",
    "]\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2b5aa1",
   "metadata": {},
   "source": [
    "Idea 2:\n",
    "\n",
    "have the agent manage its own memory, and encourage it to get creative with using a tool that allows it to write to a file storage API. \n",
    "\n",
    "the api manages a markdown file. \n",
    "\n",
    "could the agent come up with really cool and interesting data storage methods? \n",
    "\n",
    "should the api be elaborate, or should it just be \"here's the whole file, write back too it what you want\".. \n",
    "\n",
    "API includes\n",
    "\n",
    "get all \"section\" headers"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
